{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/22 14:50:11 WARN Utils: Your hostname, alex-Lenovo-Legion-5-15IMH05H resolves to a loopback address: 127.0.1.1; using 192.168.1.40 instead (on interface wlp0s20f3)\n",
      "23/10/22 14:50:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/22 14:50:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"TPC-DS Data Loading\").config(\"spark.sql.catalogImplementation\", \"hive\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/22 14:50:13 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "23/10/22 14:50:13 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "23/10/22 14:50:18 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "23/10/22 14:50:18 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore alex@127.0.1.1\n",
      "23/10/22 14:50:18 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException\n",
      "23/10/22 14:50:19 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/22 14:50:20 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:20 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "23/10/22 14:50:20 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "23/10/22 14:50:20 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "23/10/22 14:50:20 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "23/10/22 14:50:20 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/call_center specified for non-external table:call_center\n",
      "23/10/22 14:50:20 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:20 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/catalog_page specified for non-external table:catalog_page\n",
      "23/10/22 14:50:20 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:20 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/catalog_returns specified for non-external table:catalog_returns\n",
      "23/10/22 14:50:20 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:20 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/catalog_sales specified for non-external table:catalog_sales\n",
      "23/10/22 14:50:20 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:20 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/customer specified for non-external table:customer\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/customer_address specified for non-external table:customer_address\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/customer_demographics specified for non-external table:customer_demographics\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/date_dim specified for non-external table:date_dim\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/household_demographics specified for non-external table:household_demographics\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/income_band specified for non-external table:income_band\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/inventory specified for non-external table:inventory\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/item specified for non-external table:item\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/promotion specified for non-external table:promotion\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/reason specified for non-external table:reason\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/ship_mode specified for non-external table:ship_mode\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/store specified for non-external table:store\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/store_returns specified for non-external table:store_returns\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/store_sales specified for non-external table:store_sales\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/time_dim specified for non-external table:time_dim\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/warehouse specified for non-external table:warehouse\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/web_page specified for non-external table:web_page\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/web_returns specified for non-external table:web_returns\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/web_sales specified for non-external table:web_sales\n",
      "23/10/22 14:50:21 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/10/22 14:50:21 WARN HiveMetaStore: Location: file:/home/alex/Projet%20DW/DataWarehouse-SparkSQL/spark-warehouse/web_site specified for non-external table:web_site\n"
     ]
    }
   ],
   "source": [
    "#create all tables\n",
    "with open(os.getcwd() + \"/Create_database.sql\", 'r') as file: # path/to/tpcds.sql\n",
    "    db_string = file.read()\n",
    "\n",
    "db_string = str.split(db_string, \";\")\n",
    "db_string = db_string[:-1]\n",
    "\n",
    "for string in db_string:\n",
    "    if string != '\\n' or string != '':\n",
    "        spark.sql(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load datas into tables\n",
    "data_file = glob.glob(os.getcwd() + \"/data/*\")\n",
    "for i in data_file:\n",
    "    table_name = i.split(\"/\")[-1].split(\".\")[0]\n",
    "    if table_name != \"dbgen_version\":\n",
    "        sql_command = \"select * from \" + table_name\n",
    "        tmp=spark.sql(sql_command)\n",
    "        #print(tmp)\n",
    "        df = spark.read.schema(tmp.schema).csv( i, sep='|')\n",
    "        df.write.mode(\"append\").insertInto(table_name)\n",
    "        print(\"Data from table\" + table_name + \"is inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'with' statement on line 4 (79727229.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    db_string = file.read()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'with' statement on line 4\n"
     ]
    }
   ],
   "source": [
    "#run queries\n",
    "queries_files = glob.glob(os.getcwd() + \"/queries/queries*\")\n",
    "for i in queries_files:\n",
    "    with open( i , 'r') as file:\n",
    "        db_string = file.read()\n",
    "        \n",
    "        #start time\n",
    "        try:\n",
    "            spark.sql(db_string)\n",
    "        except:\n",
    "            print( i + \"doesn't work\")\n",
    "        #end time\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from customer\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
